Homework 2
================
Kairui Wang
2023-09-30

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

1.  Clean the data of ‘pols-month’

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols_df = 
  read_csv("./data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

2.  Clean the data of ‘snp’

``` r
snp_df =
    read_csv(
      "./data/snp.csv", 
      col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

3.  Tidy the data of `unemployment`

``` r
unemployment_df = 
  read_csv("./data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

4.  Merge the three datasets

``` r
data_538 = 
  left_join(pols_df, snp_df) |>
  left_join(x = _, y = unemployment_df)

str(data_538)
```

    ## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

## Problem 2

1.  Creat ‘homes_powered’ variable

``` r
mr_df =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N586") |>
  janitor::clean_names() |>
  mutate(
    year = as.character(year),
    homes_powered = (weight_tons*500/30)
  )
```

2.  Clean and organize the data for Professor Trash Wheel and Gwynnda

``` r
prof_df =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M108") |>
  janitor::clean_names() |>
  mutate(
    year = as.character(year),
    homes_powered = (weight_tons*500/30)
  ) |> 
  mutate(type = 'professor trash wheel')

gwyn_df =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L157") |>
  janitor::clean_names() |>
  mutate(
    year = as.character(year),
    homes_powered = (weight_tons*500/30)
  ) |> 
  mutate(type = 'gwynnda trash wheel')
```

``` r
mr_df = mutate(mr_df, type = 'mr trash wheel')
```

3.  Combine with the Mr. Trash Wheel dataset

``` r
trash_df = 
  full_join(mr_df, prof_df) |> 
  full_join(gwyn_df)
```

The number of observations in `mr_df` dataset is 584. The names of key
variables are: dumpster, month, year, date, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered,
type.

The number of observations in `prof_df` dataset is 106. The names of key
variables are: dumpster, month, year, date, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, plastic_bags, wrappers, homes_powered, type.

The number of observations in `gwyn_df` dataset is 155. The names of key
variables are: dumpster, month, year, date, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
plastic_bags, wrappers, homes_powered, type.

The total weight of trash collected by Professor Trash Wheel is 216.26
tons. The total number of cigarette butts collected by Gwynnda in July
of 2021 is 1.63^{4}.

## Problem 3

1.  Import, clean, and tidy the dataset of baseline demographics

``` r
baseline_df = 
  read_csv("./data_mci/MCI_baseline.csv", skip = 1 ) |>
  janitor::clean_names() |>
  mutate( 
    sex = as.factor(sex),
    apoe4 = as.factor(apoe4)
    ) |> 
  filter(age_at_onset > current_age | age_at_onset == '.')
```

The number of observations that had an age of onset for MCI was 479.

The average baseline age is 65.03.

A proportion of 30 % of women in the study are APOE4 carriers.

2.Import, clean, and tidy the dataset of longitudinally observed
biomarker values

``` r
amyloid_df =
  read_csv("./data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  pivot_longer(
    time_2:time_8,
    names_to = 'time',
    values_to = 'amyloid_ratio'
  ) |>
  rename(id = study_id) |>
  mutate(amyloid_ratio = as.numeric(amyloid_ratio))
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `amyloid_ratio = as.numeric(amyloid_ratio)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

The number of observations is 1948. A total of 8 participants appear in
only the baseline dataset, and a total of 16 participants appear in only
the amyloid dataset. It suggests that there are unique ‘id’ values in
each dataset that are not shared between the two datasets.

3.Combine the demographic and biomarker datasets

``` r
MCI_df <- inner_join(baseline_df, amyloid_df, by = "id")
```

The resulting dataset has 1884 observations and 9 variables.

The average age at baseline for this group was 65.05 years.

4.Saving the combined dataset as a csv file

``` r
write.csv(MCI_df, file = "data_mci/MCI_df.csv")
```
